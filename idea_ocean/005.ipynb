{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "前一版發現不同的submission之間差異太大，004版的auto-sklearn是直接做分類，其他版是回歸然後四捨五入取整。\n",
    "本篇任務:\n",
    "1. 用回歸算，四捨五入，看能不能做voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings  \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 目錄存在，不建立。\n",
      "vis  目錄存在，不建立。\n",
      "sub  目錄存在，不建立。\n"
     ]
    }
   ],
   "source": [
    "lis = ['data', 'vis', 'sub']\n",
    "for i in lis:\n",
    "    if os.path.isdir(i):\n",
    "        print(\"%-5s目錄存在，不建立。\"%i)\n",
    "    else:\n",
    "        os.makedirs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "test_filename = './data/test.csv'\n",
    "test = pd.read_csv(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "- y = LEVEL\n",
    "- 文字: Station, County, Location\n",
    "- 有nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把Season 4的部分用眾數補起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E02' 'E03' 'E05' 'E06' 'E08' 'E09' 'HL02' 'HL03' 'HL05' 'HL06' 'HL08'\n",
      " 'HL09' 'HL11' 'HL12' 'M01' 'M02' 'M04' 'M05' 'M07' 'M08' 'M10' 'M11'\n",
      " 'M13' 'M14' 'M16' 'M17' 'M19' 'M20' 'M22' 'M23' 'N01' 'N02' 'N04' 'N05'\n",
      " 'N07' 'N08' 'N10' 'N11' 'N13' 'N14' 'N16' 'N17' 'N19' 'N20' 'N22' 'N23'\n",
      " 'SE03' 'SE04' 'SE06' 'SE07' 'SE09' 'SE10' 'SE12' 'SE13' 'SE15' 'SE16'\n",
      " 'SE18' 'SE19' 'SE21' 'SE22' 'SE24' 'SW01' 'SW03' 'SW04' 'SW06' 'SW07'\n",
      " 'SW09' 'SW10' 'SW12' 'SW13' 'SW15' 'SW16' 'SW18' 'SW19' 'SW21' 'SW22'\n",
      " 'SW24' 'SW25' 'TT02' 'TT03']\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "nan_col = df_copy.columns[df_copy.isna().any()]\n",
    "\n",
    "lis = df_copy['Station'].unique()\n",
    "print(lis)\n",
    "for i in lis:\n",
    "    cond = df_copy['Station'] == i\n",
    "    \n",
    "    df_copy.loc[cond, nan_col] = df_copy.loc[cond, nan_col].fillna(0, axis = 0)\n",
    "    df_copy.loc[cond, nan_col] = df_copy.loc[cond, nan_col].mode().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              大溪\n",
       "1              大溪\n",
       "2              大溪\n",
       "3              大溪\n",
       "4              頭城\n",
       "          ...    \n",
       "314            長光\n",
       "315           白桑安\n",
       "316    白桑安/長濱觀景平台\n",
       "317    白桑安/長濱觀景平台\n",
       "318            寜埔\n",
       "Name: Location, Length: 319, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.pop('County')\n",
    "df_copy.pop('Station')\n",
    "df_copy.pop('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.copy()\n",
    "y = X.pop('LEVEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: ocean_001\n",
      "  Metric: r2\n",
      "  Best validation score: 0.424719\n",
      "  Number of target algorithm runs: 110\n",
      "  Number of successful target algorithm runs: 88\n",
      "  Number of crashed target algorithm runs: 3\n",
      "  Number of target algorithms that exceeded the time limit: 19\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "Accuracy score 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.regression as auto_reg\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import pickle\n",
    "import numpy as np\n",
    "# X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    sklearn.model_selection.train_test_split(X, y, test_size = 0.3, random_state=12)\n",
    "\n",
    "automl = auto_reg.AutoSklearnRegressor(\n",
    "    time_left_for_this_task=1000,\n",
    "    per_run_time_limit=200,\n",
    "#     tmp_folder='./tmp/autosklearn_parallel_1_example_tmp',\n",
    "#     output_folder='./tmp/autosklearn_parallel_1_example_out',\n",
    "#     include_estimators = ['random_forest', 'libsvm_svc', ],\n",
    "#     resampling_strategy='holdout',\n",
    "#     resampling_strategy_arguments={'train_size': 0.8},\n",
    "    resampling_strategy='cv',\n",
    "    resampling_strategy_arguments={'folds': 5},\n",
    "    ensemble_nbest = 30, \n",
    "    \n",
    "    \n",
    "    n_jobs=8,\n",
    "    # Each one of the 4 jobs is allocated 3GB\n",
    "    memory_limit=10240,\n",
    "    seed=5,\n",
    ")\n",
    "automl.fit(X_train, y_train, dataset_name='ocean_001')\n",
    "\n",
    "# Print statistics about the auto-sklearn run such as number of\n",
    "# iterations, number of models failed with a time out.\n",
    "print(automl.sprint_statistics())\n",
    "y_hat = automl.predict(X_test)\n",
    "y_hat = np.ceil(y_hat).astype('int')\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))\n",
    "\n",
    "\n",
    "\n",
    "# save model\n",
    "with open('./tmp/iris-classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f)\n",
    "\n",
    "# load model\n",
    "with open('./tmp/iris-classifier.pkl', 'rb') as f:\n",
    "    loaded_classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E04_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LEVEL\n",
       "0  E01_1    NaN\n",
       "1  E01_2    NaN\n",
       "2  E01_3    NaN\n",
       "3  E01_4    NaN\n",
       "4  E04_1    NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filename = './data/test.csv'\n",
    "df = pd.read_csv(test_filename)\n",
    "\n",
    "tmp = pd.read_csv('data/submission.csv')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把地理因素補起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E01' 'E04' 'E07' 'HL01' 'HL04' 'HL07' 'HL10' 'LI10' 'M03' 'M06' 'M09'\n",
      " 'M12' 'M15' 'M18' 'M21' 'M24' 'N03' 'N06' 'N09' 'N12' 'N15' 'N18' 'N21'\n",
      " 'N24' 'SE05' 'SE08' 'SE11' 'SE14' 'SE17' 'SE20' 'SE23' 'SW02' 'SW05'\n",
      " 'SW08' 'SW11' 'SW14' 'SW17' 'SW20' 'SW23' 'TT01' 'TT04']\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "nan_col = df_copy.columns[df_copy.isna().any()]\n",
    "\n",
    "lis = df_copy['Station'].unique()\n",
    "print(lis)\n",
    "for i in lis:\n",
    "    cond = df_copy['Station'] == i\n",
    "    \n",
    "    df_copy.loc[cond, nan_col] = df_copy.loc[cond, nan_col].fillna(0, axis = 0)\n",
    "    df_copy.loc[cond, nan_col] = df_copy.loc[cond, nan_col].mode().values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 做submmision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       石城\n",
       "1       石城\n",
       "2       石城\n",
       "3       石城\n",
       "4       永鎮\n",
       "      ... \n",
       "158    八仙北\n",
       "159    石雨傘\n",
       "160    石雨傘\n",
       "161    石雨傘\n",
       "162    石雨傘\n",
       "Name: Location, Length: 163, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.pop('County')\n",
    "df_copy.pop('Station')\n",
    "df_copy.pop('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('./tmp/iris-classifier.pkl', 'rb') as f:\n",
    "    loaded_classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-06-05 17:09:20'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now_time = datetime.datetime.now()\n",
    "now_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "now_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_classifier.predict(df_copy)\n",
    "y_pred = np.ceil(y_pred).astype('int')\n",
    "\n",
    "tmp = pd.read_csv('data/submission.csv')\n",
    "tmp.loc[:, 'LEVEL'] = y_pred\n",
    "tmp.to_csv('./sub/'+now_time+'_auto_sklearn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_report(test_report):\n",
    "    lists = os.listdir(test_report)                                    #列出目錄的下所有文件和文件夾保存到lists\n",
    "    print(list)\n",
    "    lists.sort(key=lambda fn:os.path.getmtime(test_report + \"/\" + fn))#按時間排序\n",
    "    file_new = os.path.join(test_report,lists[-1])                     #獲取最新的文件保存到file_new\n",
    "    print(file_new)\n",
    "    return file_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "sub/2021-06-05 17:09:20_auto_sklearn.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_report=\"sub\"   #目錄地址\n",
    "    new_report(test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "sub/2021-06-05 17:09:20_auto_sklearn.csv\n",
      "False\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv(new_report(test_report))['LEVEL']\n",
    "b = pd.read_csv('sub/auto_sklearn (1).csv')['LEVEL']\n",
    "\n",
    "\n",
    "print(np.array_equiv(a,b))\n",
    "tmp = np.where(a!=b)[0]\n",
    "print(len(tmp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "兩個答案不重複的這麼多? 實際上差異的東西看起來會不會是排名上差1或2? 是否表示跟排名上有些許差異。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 6 6 6 5 6 5 5 4 5 4 5 6 4 5 5 4 4 4 5 5 5 4 5 6 4 7 7 7 7 8 7 7 7 7 7\n",
      " 7 7 5 5 5 6 7 7 6 5 6 5 5 4 5 5 5 6 7 7 7 6 5 4 4 4 7 6 7 7 6 6 5 7 7 7 7\n",
      " 7 6 5 5 5 4 3 4 4 5 4 5 4 4 4 4 4 6 6 6 7 6 5 7 6 7 6 6 6 6 6 6 5 4 4 4 6\n",
      " 5 7 5 6 6 5 8 8 8 6 7 7 7 5 4 3 4 3 5 4 6 5]\n",
      "[ 2  7  7  7  4  2  1  2  2  1  1  2  2  7  2  7  1  2  2  2  7  1  2  2\n",
      "  7  7  2  6 10  6  6 10  6 10  6  6  6  6  6  2  2  2 10  6 10  2  2 10\n",
      "  2  2  2  2  2  2  2  9  9  9  8  2  2  2  2  9  2  8  8  9  2  2  8  8\n",
      "  8  8  8  2  2  2  2  2  2  2  2  7  1  1  1  2  2  2  2  5  7  5  5  1\n",
      "  1  3  5  3  3  5  5  5  7  5  3  3  3  3  7  2  9  2  5  2  2  6  6  9\n",
      "  5  6  6  6  2  1  1  2  2  2  2  7  2]\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "print(a[np.where(a!=b)[0]].values)\n",
    "print(b[np.where(a!=b)[0]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
